# ============================================
# 数据爬取任务 (Data Crawling Tasks)
# ============================================

# 每天凌晨4点执行 HungryPanda 爬虫任务（抓取所有店铺订单，随机延迟1-5分钟）
0 4 * * * /bin/bash -c 'sleep $((60 + RANDOM % 240)) && curl -s -X POST http://api:8000/run/crawler -H "Content-Type: application/json" -d '"'"'{"platform":"panda","store_code":"all"}'"'"' >> /var/log/cron-panda.log 2>&1'

# 每天凌晨5点执行 Deliveroo 爬虫任务（抓取所有店铺订单，随机延迟1-5分钟）
0 5 * * * /bin/bash -c 'sleep $((60 + RANDOM % 240)) && curl -s -X POST http://api:8000/run/crawler -H "Content-Type: application/json" -d '"'"'{"platform":"deliveroo","store_code":"all"}'"'"' >> /var/log/cron-deliveroo.log 2>&1'

# ============================================
# 每日汇总计算任务 (Daily Summary Calculation)
# ============================================

# 每天凌晨6点执行 Deliveroo 每日汇总爬取（等待5点订单爬虫完成，抓取昨天的汇总数据）
0 6 * * * /bin/bash -c 'sleep 300 && curl -s -X POST http://api:8000/run/deliveroo/daily-summary -H "Content-Type: application/json" -d '"'"'{"stores":["all"],"date":"$(date -d yesterday +\%Y-\%m-\%d)"}'"'"' >> /var/log/cron-deliveroo-summary.log 2>&1'

# 每天凌晨6点10分执行 HungryPanda ETL 计算（从 raw_orders 计算昨天的每日汇总）
10 6 * * * /bin/bash -c 'sleep 60 && curl -s -X POST http://api:8000/run/panda/daily-summary -H "Content-Type: application/json" -d '"'"'{"store_code":"all","date":"$(date -d yesterday +\%Y-\%m-\%d)"}'"'"' >> /var/log/cron-panda-summary.log 2>&1'

# ============================================
# 飞书推送任务 (Feishu Notification)
# ============================================

# 每天早上9点发送昨日订单汇总（示例，可根据需要启用）
0 9 * * * curl -s -X POST http://api:8000/reminder/daily-summary >> /var/log/cron-feishu.log 2>&1

